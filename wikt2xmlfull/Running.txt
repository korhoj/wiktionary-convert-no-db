You need to first compile (I used Eclipse) the three Java programs ("apps", if you prefer) used for processing the Wiktionary dump(s) for the languages you want to process.
  The programs are: StripNamespaces, ReadStripped and JoinDefinitions
See Build.txt.

To process the dumps with the Java programs and the scripts I have written, you will need to have both a Windows and Linux environment, either real or virtual ones.  
The Windows scripts are *.cmd scripts, using the syntax for the older Command Prompt (cmd.exe), not PowerShell as such.
I haven't tested using WSL or WSL2 for the Linux portion of the process. One of the steps uses a GUI program. I use a virtual Ubuntu image in VMware WS. You can of course run Linux in another virtualizer such as VirtualBox, or use a machine running Linux.

The Windows scripts use environment variables for determining the input and output folder and constructing the file names to use. Since I make new conversions for various languages every now and then, I have defined the variables permanently for my user account (you can also of course define them for all user accounts by defining "System variables"). 
  You can alternatively define the env variables each time you open a Command Prompt (cmd.exe) for running a script(s), by using the SET command, but these instructions assume the permanent definition style. 

To define environment variables for your user account in e.g. Windows 10, click the Search icon, usually located in the lower-left region of the task bar, and type something like "envi" (or if you use Windows in a different language, something that refers to environment variables in your language), and from the search results, under the heading "Settings", pick "Edit environment variables for your account".

Click New to create each variable below, and set them to point to the folder you want to use. N.b. create the folders yourself, if they don't already exist:
  Variable   Example value               Description
  DICT       G:\Temp\wiktionary-dumps    Place each dump file (.bz2) you will download here
  JAVA_HOME  C:\Usr\jdk-22               Define where your JDK is placed
  WIKT       G:\Dropbox\Dictionary\wikt  Place the JAR files for running the Java apps here
  WIKTGIT    C:\Users\korho\git\wiktionary-convert-no-db\wikt2xmlfull
                                         The Eclipse workspace location for the wikt2xmlfull project

Next you will download and extract the Wiktionary articles dump of one or more of the languages supported by wikt2xmlfull:
  English (en), Finnish (fi), Norwegian Nynorsk (nn), Norwegian (no), Swedish (sv)

Not fully supported yet: Greek (el)
  (I was asked to convert the Greek wikt, but I had trouble parsing the entries)
Not supported yet: Albanian (sq)
  (I was asked to convert the Albanian wikt, but I had trouble parsing the entries)

The completed dumps are listed at https://dumps.wikimedia.org/backup-index.html,
although you really should use one of the mirrors, so you won't strain the default servers, and downloading is also probably faster. I'm currently using a Swedish mirror:
  https://mirror.accum.se/mirror/wikimedia.org/dumps/

It contains links to subdirectories for each language for each Wiki project (Wikibooks, Wikimedia, Wiktionary etc.). wikt2xmlfull only supports Wiktionary dumps though (and only for some few languages - see above).

In the directory listing, search for the link to the subdirectory of the Wiktionary dump for the language you want to download the dump for. 
  E.g. search for "enwiktionary" (the exact name is "enwiktionary/") for the link to the English Wiktionary dump directory. For the Swedish mirror, the (permanent) link is:
  https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/
Open the link in a browser (e.g. Edge, Firefox or Chrome). You get a new directory listing, which contains the available dumps listed by date.
Note that the Wikimedia foundation makes dumps in a recurring process, happening about twice a month, and when it's ongoing, dumps for different languages naturally are finished at different times. I personally like to download the latest dump of each language, whether they are extracts for the same day or not. 

Currently (@20240926-07.31 UTC+2) the latest English dump is for the date 20240901,
but say the latest Finnish dump is for 20240920.

Open the link to the subdirectory for the language - date -combination you selected, i.e. for the English Wiktionary currently:
  https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/20240901/

Sometimes the dump is not ready even though the directory exists already. To be sure, open the link to the file status.html in the directory listing. E.g. 
  https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/20240901/status.html
It should have a text like this:
  * 2024-09-06 02:28:29 enwiktionary: Dump complete

(where the word "enwiktionary" is currently a slightly _malformed_ link, https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/20240901/enwiktionary/20240901, - it's supposed to just point to the dump directory the status.html file is in...)

If the dump isn't complete, you naturally need to use the dump for another date. You probably want to open the dump directory for the second latest date in the listing - currently "20240820":
  https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/20240820/

Download the file named with the naming scheme
  xxwiktionary-yyyymmdd-pages-articles.xml.bz2 (where xx is the language code)
e.g. enwiktionary-20240901-pages-articles.xml.bz2. E.g.:
  https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/20240901/enwiktionary-20240901-pages-articles.xml.bz2
Store the downloaded dump file to the directory pointed by the variable DICT (%DICT%) you defined earlier on.

N.b. make sure to download the -pages-articles.xml.bz2 file, not either of these two files with a partly similar naming scheme:
  - xxwiktionary-yyyymmdd-pages-articles-multistream-index.txt.bz2
  - xxwiktionary-yyyymmdd-pages-articles-multistream.xml.bz2 

N.b. You can theoretically instead download the latest finished dump for a language by accessing the dump file in a "/latest/" subdirectory. E.g.: 
  https://dumps.wikimedia.org/enwiktionary/latest/enwiktionary-latest-pages-articles.xml.bz2
but don't do that, because the scripts I have written for processing the dump of each supported language use a naming scheme based on the dump date, and the "latest" dump file (.bz2) doesn't contain information for which date the dump is for (so you would need to find out that by investigating the above mentioned dump directories anyway, e.g. .../20240901/).

In the DICT directory, extract each bz2 file you downloaded into it's own subdirectory. Use the name of the .bz2 dump file as the name of the subdirectory.

I use 7-Zip via Windows' Explorer by right-clicking each .bz2 file and selecting the action Extract to "xxwiktionary-yyyymmdd-pages-articles.xml\". E.g. for the latest English dump file:
  7-Zip > Extract to "enwiktionary-20240901-pages-articles.xml\"
You don't need the bz2 dump file after extracting it. The input file you just extracted won't be changed when it's processed.

Next you will be using various Windows cmd (*.cmd) scripts for processing the files you downloaded and extracted.
The scripts are in the Eclipse workspace under the folder Scripts.
Each kind of script is in its own subfolder, e.g. StripNamespaces\
In my system, the full path to the StripNamespaces folder is:
  G:\Users\Joel\git\wiktionary-convert-no-db\wikt2xmlfull\Scripts\StripNamespaces\
Open a Windows Command Prompt (cmd.exe) and go to the StripNamespaces folder:
  CD /D "%WIKTGIT%"\Scripts\StripNamespaces

A. COMPILING THE ENGLISH WIKTIONARY, WITH ENTRIES FOR ALL LANGUAGES

1. Change EDITION to match with the Wiktionary edition you have downloaded in
StripNamespaces ALL.cmd.
  It is currently defined in the line number 18:
  
  set EDITION=20240901

2. Using the StripNamespaces program 

If you have Eclipse open, at this point you may want to close it, to release memory and CPU resources. Then:

Run StripNamespaces ALL.cmd in the Command Prompt (or start it e.g. double-clicking the script file in Windows Explorer).

StripNamespaces prints first what it is going to process and produce, and the start time
  "EDITION: 20240901"
  "PROG: G:\Dropbox\Dictionary\wikt\StripNamespaces.jar"
  "INFILE: G:\Temp\wiktionary-dumps\enwiktionary-20240901-pages-articles.xml\enwiktionary-20240901-pages-articles.xml"
  "OUTFILE: G:\Temp\wiktionary-dumps\enwiktionary-20240901-pages-articles.xml\stripped-ALL.xml"
syysk. 26, 2024 8:28:19 AP. wiktionary.to.xml.full.StripNamespaces main
  ("syysk." is an abbreviation for September in the Finnish language, and "AP." for "am"...)

StripNamespaces prints progress every 10 000 entries. If the printing bothers you, you can minimize the window and check every now and then whether the stripping has finished. 

Stripping the English Wiktionary takes long even on a fast computer. It takes currently
(20240926) about 55 mins for the about xxxx entries in the dump.

When the stripping finishes, for convenience the start time is printed again, and the 
finish time is printed, so you can see how long the processing took.
E.g. for the English Wiktionary:
  syysk. 26, 2024 9:23:22 AP. wiktionary.to.xml.full.StripNamespaces process
  INFO: Processed entry 8130000 [shouldn't this be a larger number??]
  Ready 
TODO: update the above printout

E.g. for the Greek Wiktionary:
	syysk. 26, 2024 10:56:10 AP. wiktionary.to.xml.full.StripNamespaces process
	INFO: Processed entry 1530000
	Ready
	  Conversion started at 2024-09-26-10-53-59
	  Params were:
	    "C:\Usr\jdk-22\bin\java.exe" -Dfile.encoding=UTF8 -Xmx2600M -Xss400M -jar "G:\Dropbox\Dictionary\wikt\StripNamespaces.jar" "G:\Temp\wiktionary-dumps\elwiktionary-20240901-pages-articles.xml\elwiktionary-20240901-pages-articles.xml" "G:\Temp\wiktionary-dumps\elwiktionary-20240901-pages-articles.xml\stripped-ALL.xml"
	  Conversion ended at 2024-09-26-10-56-10

3. Using the ReadStripped program 

Running the ReadStripped program uses a language specific script which calls a
general script common to all languages. (SD in the script names == StarDict)
E.g.:

1) ReadStripped SD en-ALL.cmd
  Process the English Wiktionary, all languages
2) ReadStripped SD en-en.cmd
  Process the English Wiktionary, English only
--> the scripts above call automatically a general script:
3) ReadStripped SD ALL.cmd

The MEM and/or STCK variables in the ReadStripped SD ALL.cmd script file have been set as
-Xmx2600M and -Xss400M which should suffice for one pass. The reason for restarts is indeed
that not so much memory is required. Each restart continues processing where the previous
run left off.

Change EDITION to match with the Wiktionary edition you have downloaded in e.g.
ReadStripped SD en-ALL.cmd and run it. E.g.:
  set EDITION=20240901

B. COMPILING A WIKTIONARY OF ANOTHER LANGUAGE

There are one or two sample script files for each supported language. They really only differ in having
different language specific variables set. I use the Finnish Wiktionary as an example:

Change EDITION in "StripNamespaces fiwiktionary.cmd" to match with the Wiktionary edition you have downloaded.

Run StripNamespaces fiwiktionary.cmd. It doesn't take many minutes on a fast computer.

Change EDITION to match with the Wiktionary edition you have downloaded, in either

1) ReadStripped SD fi-ALL.cmd
  Process the Finnish Wiktionary, all languages
or
2) ReadStripped SD fi-fi.cmd
  Process the Finnish Wiktionary, Finnish only

Then run the script you changed.

C. UPDATING LANGUAGES SUPPORTED BY ReadStripped

When you export the runnable JAR in Eclipse, the *.csv files in src/ get packaged
in the JAR. They are CSV files containing the language codes (unique abbroviations) and names
used in Wiktionaries of various languages.   

While running, ReadStripped reads in, based on the parameters, one of the CSV files.

The program rejects any unknown language names and outputs them into "new language codes.csv".
You can check that file and insert any new languages into the CSV you used.

If you don't want entries of some languages to be included, you can remove them from your
copy of the CSV file you used. Just don't commit it :) E.g. I don't need entries for various
Asian languages, since I can't even read their scripts.

N.b. this has nothing to do with which language's Wiktionaries the program supports, which
is currently hard coded in the program.

All Wiktionaries have entries for numerous languages. Just that e.g. the English
Wiktionary has the definitions of the entries in the English language.

D. COMBINING THE OUTPUT FILES

I perform the steps in D and E in Linux running Ubuntu 22.04 LTS. I run it inside VMware Workstation.

dos2unix
--------
You need to have dos2unix installed. If you don't have it yet, install it:

$ sudo apt install dos2unix

Copying files from git to Linux
-------------------------------
Copy any dictionary files you have produced above (by running the ReadStripped*.cmd script for the language you are processing) to your Linux to a directory of your choice.
These have a name in the format wikt-langcode-lang-yyyy-mm-dd-hh-mm-ss.txt
E.g.: wikt-en-ALL-2023-02-18-13-22-03.txt, wikt-en-ALL-2023-02-18-13-26-43.txt etc.

Also copy to the same directory the scripts conv2unix*.sh, dictfmt*.sh and sort*.sh from your checked out Git repository for wiktionary-convert-no-db to Linux.

I do the copying by using the shared folders feature of VMware Workstation.
Alternatively, you could checkout my git repository using your Linux.

conv2unix scripts
-----------------
Edit the date of the input files to the conv2unix*.sh script for the dictionary language you are processing, e.g.

# for en-ALL:
$ vi conv2unix-en-ALL.sh
# for fi-fi:
$ vi conv2unix-fi-fi.sh

In the file, the input files for a given date are specified like this:
  convDate="2023-02-18*"

Run the conv2unix-*.sh script for the language you are processing. E.g.:

# for en-ALL
$ conv2unix-en-ALL.sh
# for fi-fi
$ conv2unix-fi-fi.sh

Or run scripts for all supported languages:
  for f in `ls conv2unix-*.sh` ; do echo $f && ./$f ; done

The conv2unix script(s) produce(s) output unsorted output files, which shows in the file names,
which are of the format wikt-langcode-lang-unsorted.txt.
E.g. for en-ALL the file is wikt-en-ALL-unsorted.txt 

sorting
-------
The unsorted file(s) produced by conv2unix script(s) need to be sorted to be further processed.

Before doing this by running any of the sort*.sh scripts for the language whose dictionary you are processing, make sure you have the locale(s) you need.
First check, which locale the script(s) use(s), e.g.:

sort-el-el.sh has this definition:
  export LC_ALL=el_GR.UTF-8
Which means you need the locale el_GR.utf8 in your system.

Check, which locales are already available:

$ locale -a
  C
  C.utf8
  el_GR.utf8
  en_AG
  en_AG.utf8
  en_AU.utf8
  en_BW.utf8
  en_CA.utf8
  en_DK.utf8
  en_GB.utf8
  en_HK.utf8
  en_IE.utf8
  en_IL
  en_IL.utf8
  en_IN
  en_IN.utf8
  en_NG
  en_NG.utf8
  en_NZ.utf8
  en_PH.utf8
  en_SG.utf8
  en_US.utf8
  en_ZA.utf8
  en_ZM
  en_ZM.utf8
  en_ZW.utf8
  fi_FI.utf8
  nb_NO.utf8
  nn_NO.utf8
  POSIX
  sv_SE.utf8

If a locale you need is not available, generate it, e.g.:

$ sudo localedef -f UTF-8 -i el_GR el_GR.UTF-8
$ sudo localedef -f UTF-8 -i fi_FI fi_FI.UTF-8
$ sudo localedef -f UTF-8 -i sv_SE sv_SE.UTF-8

The sort*.sh parse (unless you change them) the input files for the current date for a given dictionary language, produced above by running the corresponding conv2unix shell script.

Run the sort script for the language you are processing, e.g.:

# for en-ALL
$ sort-en-ALL.sh
# for fi-fi
$ sort-fi-fi.sh

Or run scripts for all supported languages:
  for f in `ls sort-*.sh` ; do echo $f && ./$f ; done

The sort script produces output named according to the language you are processing. E.g. for en-ALL the file is named in the format:
  wikt-en-ALL-yyyy-mm-dd.txt

E. PARSING THE ENTRIES AND CREATING STARDICT FILES

stardict-tools
==============
Ubuntu repos for 22.04 LTS and 24.04 LTS have a working stardict-tools (and stardict) package.
  22.04 LTS: 3.0.7+git20211225+dfsg-1 (@20230218)
  24.04 LTS: 3.0.7+git20220909+dfsg-4build4 (@20240917)
So there is no need to build it oneself anymore.

$ sudo apt install stardict-tools

See https://stardict-4.sourceforge.net/ChangeLog (link is in https://stardict-4.sourceforge.net/index_en.php)
  2022.
    StarDict-3.0.1.3 (Bodhisatta xxx) released.
    Support compress dictionary format!
    Some small changes!
  2022.1.
    StarDict-3.0.7 (MasterWork xxx) released.
    Port to gtk3!
    Add some babylon dictionaries.
    Add some BigDict dictionaries.
    Add some PowerWord dictionaries.
    Stardict_client add md5 salt feature and RSA encrypt feature! As StarDict-Protocol_v04.
    Thanks Anatoly Sova <anatoliysova@gmail.com> for the bgl and dsl convert patch!
    Add fortune and cal plugins.
    Add info plugin.
    Add flite TTS plugin.
    Add YouDao.com netdict plugin.
    Thanks GreenLunar for the Hebrew translation!
    Many small changes.

Optionally you may install the whole stardict package:

$ sudo apt install stardict stardict-gtk stardict-plugin stardict-plugin-espeak \
 stardict-plugin-festival stardict-plugin-info stardict-plugin-spell stardict-xmllittre

stardict-editor
===============
Run "stardict-editor" after installing it from the Ubuntu package stardict-tools (see above).

In my Ubuntu 22.04 LTS, it installed to /usr/lib/stardict-tools/ and is run like this:

$ /usr/lib/stardict-tools/stardict-editor

In the default Compile tab, press Browse and select the sorted file, e.g.
  wikt-en-ALL-yyyy-mm-dd.txt
Press Compile. The window is greyed out until processing is ready.
  If it's a big dictionary, Ubuntu may show once or many times a dialog asking
  whether you want to "Force Quit" or "Wait". Click always "Wait".
The program prints messages like this, if the conversion works:
  Building...
  [message] Conversion is over.
  [message] wikt-sv-sv-2023-02-18 wordcount: 359441.
  Done!
The program may give warnings about missing tabs for some lines but that should be ok.
The warnings look like this:
  [warning] Warning: line 12345, no tab! Skipping line.

The above conversion process produces files like:

wikt-en-ALL-yyyy-mm-dd.dict.dz
  The Stardict compatible dictionary file (for dictd compatible ones, see
   section F. below)
wikt-en-ALL-yyyy-mm-dd.idx
  The index file needed by Stardict and dictd
wikt-en-ALL-yyyy-mm-dd.ifo
  The Stardict compatible description file. It can be edited in a text editor

An example:
  
~/Downloads/stardict-tools-3.0.2/src/example.ifo:
  StarDict's dict ifo file
  version=2.4.2
  wordcount=100
  idxfilesize=100
  bookname=example
  author=the author name
  email=author@email
  website=this dictionary's project website link
  description=convert to StarDict by...
  date=2003.05.10
  sametypesequence=m

The generated ifo file, e.g. wikt-el-ALL-2023-01-19.ifo, looks something like this:

StarDict's dict ifo file
version=2.4.2
wordcount=843850
idxfilesize=20955842
bookname=wikt-el-ALL-2023-02-19
sametypesequence=m

Change the generated ifo file to look something like this:

StarDict's dict ifo file
version=2.4.2
wordcount=843850
idxfilesize=20955842
bookname=wikt-el-ALL-2023-02-19
author=Wiktionary volunteers. Converted by Joel Korhonen
email=stardict-korhoj@outlook.com
website=https://dictinfo.com
description=Stardict format, Greek Wiktionary, all languages, v.2023-Feb-19, based on entries from 2022-Nov-20
date=2023.02.19
sametypesequence=m

Creating 7z files for distributing
==================================
Run cp-StarDict-files-to-subdirs-and-compress.sh:
  #!/bin/bash
  DATENOW=`date +%Y-%m-%d`
  cp_and_compress() {
    cp -v wikt-$LANG-$LCODE-$DATENOW.{dict.dz,idx,ifo} $LANG-StarDict
    cd $LANG-StarDict/
    7z a wikt-$LANG-$LCODE-$DATENOW.7z wikt-$LANG-$LCODE-$DATENOW.{dict.dz,idx,ifo}
    cd ..
  }

  LANG=el && LCODE=ALL && cp_and_compress
  LCODE=el && cp_and_compress

  LANG=en && LCODE=ALL && cp_and_compress
  LCODE=en && cp_and_compress

  LCODE=Western && cp_and_compress

  LCODE=Western_Greek_Slavonic && cp_and_compress

  LANG=fi && LCODE=ALL && cp_and_compress
  LCODE=fi && cp_and_compress
  
  LANG=nn && LCODE=ALL && cp_and_compress
  #LCODE=nn && cp_and_compress
  
  LANG=no && LCODE=ALL && cp_and_compress
  LCODE=no && cp_and_compress

  LANG=sv && LCODE=ALL && cp_and_compress
  LCODE=sv && cp_and_compress

You may copy and unarchive the 7z files containing wikt-en-ALL-yyyy-mm-dd.dict.dz and wikt-en-ALL-yyyy-mm-dd.idx to e.g. your phone and use it with a Stardict compatible
GUI such as Colordict, or if you have installed the Stardict GUI in your PC, you can use the file with it.

F. CREATING AND INSTALLING A DICTD COMPATIBLE DICTIONARY ARCHIVE FOR A LANGUAGE

Steps in the above section D. (not necessarily E. however) need to be performed first.
Then perform the following steps in Linux:

dictzip
=======
In Ubuntu, you need to have dictzip installed to produce the .dict.dz files.
At least in 24.04 LTS, it was already installed automatically, when stardict-editor was installed.

If it is not installed for some reason, install it with apt, like normally: 

$ sudo apt install dictzip

dictd
=====
For building dictd compatible dictionary archives, you don't need to be running a dictd server. It is good to install it though, because it can be used to verify the integrity of any dictionary archives you produce. In addition you can also then use the command "dict" to look up dictionary entries in your Linux...

$ sudo apt install dictd

Dictionary packages for dictd in Ubuntu
=======================================
Ubuntu repo(s) contain many prebuilt dictionaries for dictd.
You may install any you want. It works best if you only install one or two at a time.

Some example packages for 22.04 LTS (@20230218):
  sudo apt install dict-freedict-eng-fra \
                   dict-freedict-lat-eng \
                   dict-freedict-swe-deu \
                   dict-freedict-swe-lat \
                   dict-freedict-eng-spa \
                   dict-freedict-swe-eng \
                   dict-freedict-fin-nld \
                   dict-freedict-ita-deu \
                   dict-de-en

dictfmt
=======
Install dictfmt if it is not installed:

$ sudo apt install dictfmt

Joining duplicates
==================
Run the join-dupls-dictfmt-*.cmd script in Windows for the language archive you are producing. The scripts use a Java program placed in the file JoinDefinitions.jar.

E.g. for en-ALL the script is:
  join-dupls-dictfmt-en-ALL.cmd

The script(s) produce(s) files named in the format
  wikt-langcode-lang-dictfmt-dupls-joined.txt
E.g.
  wikt-en-ALL-dictfmt-dupls-joined.txt
  
(
    toformat.txt - an example in F.O.L.D.O.C. format
	\n's should be replaced by real Unix-linefeeds (real \n's) + tab (\t)
	  sed 's/\\n/\n\t/g' > sed-test.txt < headi-nodupls.txt
)

dictfmt
=======
N.b. the next step overwrites any .dz file created in step E, e.g. wikt-en-ALL-yyyy-mm-dd.dict.dz

# for en-ALL
$ cd en/
$ ./dictfmt-en-ALL.sh

dictfmt-en-ALL.sh:
  #!/bin/bash
  convLangCode="en"
  convLang="ALL"
  #convDate="2023-02-19"
  convDate=`date +%Y-%m-%d`
  cp ../pd-header.txt wikt-$convLangCode-$convLang-$convDate-dict.txt
  cat ../wikt-$convLangCode-$convLang-dictfmt-dupls-joined.txt | tee -a wikt-$convLangCode-$convLang-$convDate-dict.txt > /dev/null
  dictfmt -f --utf8 --allchars wikt-$convLangCode-$convLang-$convDate -u http://dictinfo.com -s wikt-$convLangCode-$convLang-$convDate < wikt-$convLangCode-$convLang-$convDate-dict.txt
  dictzip wikt-$convLangCode-$convLang-$convDate.dict
  chmod 644 wikt-$convLangCode-$convLang-$convDate.dict.dz
  chmod 644 wikt-$convLangCode-$convLang-$convDate.index
  7z a wikt-$convLangCode-$convLang-$convDate-dictd.7z wikt-$convLangCode-$convLang-$convDate.{dict.dz,index}

# for fi-fi
$ cd fi/
$ ./dictfmt-fi-fi.sh

Run the script. It first copies a the public domain + CC-SA-BY copyright header to the output file. Then it copies the joined duplicates after the copyright header. The resulting file, wikt-$convLangCode-$convLang-$convDate-dict.txt, is fed as input to dictfmt:
  # For illustrative purposes, don't do manually but call the script instead
  dictfmt -f --utf8 --allchars wikt-$convLangCode-$convLang-$convDate -u http://dictinfo.com -s wikt-$convLangCode-$convLang-$convDate < wikt-$convLangCode-$convLang-$convDate-dict.tx
    -f: FILE  is  formatted  with  the headwords starting in column 0, with the
    definition indented at least one space (or tab character) on  subsequent lines.
    The third line starting in column 0 is taken as the first headword, and the
    first two lines starting in column 0 are treated as part of the
    00-database-info  header. This option was written to format the F.O.L.D.O.C.

dictfmt creates .dict and .index for the given language.

The script then calls dictzip to produces the .dict.dz file.
N.b. this step overwrites any existing .dict.dz file, but that
is normally not a problem. In step E such files were created
in a StarDict (but not dictd) compatible format, but in the
higher directory .., whilst in this step they are created in
the dictd format in language specific folders.

Verifying language's using ifo file(s) - optional
-------------------------------------------------
Run the following for a given language's ifo file, if you have created such by doing step E earlier, and want to verify the dictionary files. The ifo isn't needed for dictd as such:

$ /Downloads/stardict_3.0.6/tools/src/stardict-verify wikt-en-ALL.ifo
  [message] Verifying dictionary 'wikt-el-ALL-2023-02-19.ifo'...
  [message] Loading index file: 'wikt-el-ALL-2023-02-19.idx'...
  [message] Loading dictionary file: 'wikt-el-ALL-2023-02-19.dict.dz'...
  [message] Dictionary 'wikt-el-ALL-2023-02-19.ifo'. Verification result: OK.

Or to verify dictionaries for all languages, run:

$ for f in `ls wikt*.ifo` ; do ~/Downloads/stardict-3.0.6.3/tools/src/stardict-verify $f ; done

Installing dictd format dictionaries
------------------------------------
First make sure you are in the language specific subfolder, such as en/.
Then install a given languages .dict.dz archive like this:

$ sudo cp -vi wikt-en-ALL-yyyy-mm-dd.{dict.dz,index} /usr/share/dictd/
$ dictdconfig -l
  lists current dictionary entries. It should now show your new dictionary, e.g.:
  database wikt-en-ALL-2018-05-15
  {
   data  /usr/share/dictd/wikt-en-ALL-2018-05-15.dict.dz
   index /usr/share/dictd/wikt-en-ALL-2018-05-15.index
  }
$ sudo dictdconfig -w
  updates /var/lib/dictd/db.list
$ sudo service dictd restart
$ dictdconfig -l
  confirm the new dictionary is installed
$ dict -i wikt-en-ALL-yyyy-mm-dd
  Confirm that the header info shows OK. The copyright (from pd-header.txt) should be in the last paragraph

Testing looking up words in the dictionaries you have installed:

$ dict ἀβλεψία
  2 definitions found

  From wikt-el-el-2023-02-19 [wikt-el-el-2023-02-19]:

    ἀβλεψία
     n.
     (η) η αβλεψία στην πολυτονική γραφή
     Αρχαία ελληνικά n.
     1 τύφλωση
     2 (μεταφορικά) η αδυναμία να δει κάποιος κάτι
     3 το να είναι κάτι αόρατο

  From wikt-el-ALL-2023-02-19 [wikt-el-ALL-2023-02-19]:
  ...
