You need to first compile the program in Eclipse, see Build.txt
The example scripts for compiling are for Windows, but Linux could also be used
Linux with a desktop GUI (window manager) is needed for converting the output into StarDict or dictd
compatible file. I use a virtual Ubuntu image in VMware WS. You can also use another virtualizer such
as VirtualBox, or a machine running Linux.

Download one of the supported Wiktionary article dumps:

English, Finnish, Norwegian, Swedish

The completed dumps are listed at https://dumps.wikimedia.org/backup-index.html
Search for the Wiktionary dump you want, e.g. search for "enwiktionary" for the English Wiktionary dump
It's currently (@20221201) listed like this:
  2022-11-21 21:53:44 enwiktionary: Dump complete
    Where "enwiktionary" is a link to https://dumps.wikimedia.org/enwiktionary/20221120/
However, instead of the aforementioned link, you really should use one of the mirrors,
so you won't strain the default servers, and downloading is also probably faster.
I'm currently using a Swedish one:
  https://mirror.accum.se/mirror/wikimedia.org/dumps/
  For this mirror, one needs to search for the subdirectory of the wanted Wiktionary, e.g. "enwiktionary/"
  and click it to open the list of the (about five) latest dumps, and select the latest (complete) one.
  E.g. https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/20221120/
Download the bzip2 archive for the Wikt you want, e.g. enwiktionary-yyyymmdd-pages-articles.xml.bz2
  A real link example: https://mirror.accum.se/mirror/wikimedia.org/dumps/enwiktionary/20221120/enwiktionary-20221120-pages-articles.xml.bz2
You can also download the "latest" one from e.g. 
 https://dumps.wikimedia.org/enwiktionary/latest/enwiktionary-latest-pages-articles.xml.bz2
but I prefer to have the directory and unarchived file name show the edition (yyyymmdd) in it. The sample
cmd script assumes such a naming scheme.

Extract the bz2 file into a subdirectory. I use 7-Zip. You don't need the bz2 file after extracting it.

A. COMPILING THE ENGLISH WIKTIONARY, WITH ENTRIES FOR ALL LANGUAGES

Change EDITION to match with the Wiktionary edition you have downloaded in
StripNamespaces ALL.cmd.
Run StripNamespaces ALL.cmd. I like to do it via going to cmd.exe.
It prints progress every 10 000 entries.
Stripping the English Wiktionary takes long even on a fast computer. Takes currently
(2016-11) about 20 mins. Stripping the English entries is slower at first than after about
150 000 entries. There are currently about 4 960 000 entries!

Running the ReadStripped program uses a language specific script which calls a
general script common to all languages. (SD in the script names == StarDict)
E.g.:

1) ReadStripped SD en-ALL.cmd
  Process the English Wiktionary, all languages
2) ReadStripped SD en-en.cmd
  Process the English Wiktionary, English only
--> the scripts above call automatically a general script:
3) ReadStripped SD ALL.cmd

The MEM and/or STCK variables in the ReadStripped SD ALL.cmd script file have been set as
-Xmx2600M and -Xss400M which should suffice for one pass. The reason for restarts is indeed
that not so much memory is required. Each restart continues processing where the previous
run left off.

Change EDITION to match with the Wiktionary edition you have downloaded in e.g.
ReadStripped SD en-ALL.cmd and run it.

B. COMPILING A WIKTIONARY OF ANOTHER LANGUAGE

There are one or two sample script files for each supported language. They really only differ in having
different language specific variables set. I use the Finnish Wiktionary as an example:

Change EDITION in "StripNamespaces fiwiktionary.cmd" to match with the Wiktionary edition you have downloaded.

Run StripNamespaces fiwiktionary.cmd. It doesn't take many minutes on a fast computer.

Change EDITION to match with the Wiktionary edition you have downloaded, in either

1) ReadStripped SD fi-ALL.cmd
  Process the Finnish Wiktionary, all languages
or
2) ReadStripped SD fi-fi.cmd
  Process the Finnish Wiktionary, Finnish only

Then run the script you changed.

C. UPDATING LANGUAGES SUPPORTED BY ReadStripped

When you export the runnable JAR in Eclipse, the *.csv files in src/ get packaged
in the JAR. They are CSV files containing the language codes (unique abbroviations) and names
used in Wiktionaries of various languages.   

While running, ReadStripped reads in, based on the parameters, one of the CSV files.

The program rejects any unknown language names and outputs them into "new language codes.csv".
You can check that file and insert any new languages into the CSV you used.

If you don't want entries of some languages to be included, you can remove them from your
copy of the CSV file you used. Just don't commit it :) E.g. I don't need entries for various
Asian languages, since I can't even read their scripts.

N.b. this has nothing to do with which language's Wiktionaries the program supports, which
is currently hard coded in the program.

All Wiktionaries have entries for numerous languages. Just that e.g. the English
Wiktionary has the definitions of the entries in the English language.

D. COMBINING THE OUTPUT FILES

I perform the steps in D and E in Linux running Ubuntu 22.04 LTS. I run it inside VMware Workstation.

dos2unix
--------
You need to have dos2unix installed. If you don't have it yet, install it:

$ sudo apt install dos2unix

Copying files from git to Linux
-------------------------------
Copy any dictionary files you have produced above (by running the ReadStripped*.cmd script for the language you are processing) to your Linux to a directory of your choice.
These have a name in the format wikt-langcode-lang-yyyy-mm-dd-hh-mm-ss.txt
E.g.: wikt-en-ALL-2023-02-18-13-22-03.txt, wikt-en-ALL-2023-02-18-13-26-43.txt etc.

Also copy to the same directory the scripts conv2unix*.sh, dictfmt*.sh and sort*.sh from your checked out Git repository for wiktionary-convert-no-db to Linux.

I do the copying by using the shared folders feature of VMware Workstation.
Alternatively, you could checkout my git repository using your Linux.

conv2unix scripts
-----------------
Edit the date of the input files to the conv2unix*.sh script for the dictionary language you are processing, e.g.

# for en-ALL:
$ vi conv2unix-en-ALL.sh
# for fi-fi:
$ vi conv2unix-fi-fi.sh

In the file, the input files for a given date are specified like this:
  convDate="2023-02-18*"

Run the conv2unix-*.sh script for the language you are processing. E.g.:

# for en-ALL
$ conv2unix-en-ALL.sh
# for fi-fi
$ conv2unix-fi-fi.sh

Or run scripts for all supported languages:
  for f in `ls conv2unix-*.sh` ; do echo $f && ./$f ; done

The conv2unix script(s) produce(s) output unsorted output files, which shows in the file names,
which are of the format wikt-langcode-lang-unsorted.txt.
E.g. for en-ALL the file is wikt-en-ALL-unsorted.txt 

sorting
-------
The unsorted file(s) produced by conv2unix script(s) need to be sorted to be further processed.

Before doing this by running any of the sort*.sh scripts for the language whose dictionary you are processing, make sure you have the locale(s) you need.
First check, which locale the script(s) use(s), e.g.:

sort-el-el.sh has this definition:
  export LC_ALL=el_GR.UTF-8
Which means you need the locale el_GR.utf8 in your system.

Check, which locales are already available:

$ locale -a
  C
  C.utf8
  el_GR.utf8
  en_AG
  en_AG.utf8
  en_AU.utf8
  en_BW.utf8
  en_CA.utf8
  en_DK.utf8
  en_GB.utf8
  en_HK.utf8
  en_IE.utf8
  en_IL
  en_IL.utf8
  en_IN
  en_IN.utf8
  en_NG
  en_NG.utf8
  en_NZ.utf8
  en_PH.utf8
  en_SG.utf8
  en_US.utf8
  en_ZA.utf8
  en_ZM
  en_ZM.utf8
  en_ZW.utf8
  fi_FI.utf8
  nb_NO.utf8
  nn_NO.utf8
  POSIX
  sv_SE.utf8

If a locale you need is not available, generate it, e.g.:

$ sudo localedef -f UTF-8 -i el_GR el_GR.UTF-8
$ sudo localedef -f UTF-8 -i fi_FI fi_FI.UTF-8
$ sudo localedef -f UTF-8 -i sv_SE sv_SE.UTF-8

The sort*.sh parse (unless you change them) the input files for the current date for a given dictionary language, produced above by running the corresponding conv2unix shell script.

Run the sort script for the language you are processing, e.g.:

# for en-ALL
$ sort-en-ALL.sh
# for fi-fi
$ sort-fi-fi.sh

Or run scripts for all supported languages:
  for f in `ls sort-*.sh` ; do echo $f && ./$f ; done

The sort script produces output named according to the language you are processing. E.g. for en-ALL the file is named in the format:
  wikt-en-ALL-yyyy-mm-dd.txt

E. PARSING THE ENTRIES AND CREATING STARDICT FILES

stardict-tools
==============
Ubuntu repos for 22.04 LTS have a working stardict-tools (and stardict) package,
3.0.7+git20211225+dfsg-1 (@20230218). So there is no need to build it oneself anymore.

$ sudo apt install stardict-tools

See https://stardict-4.sourceforge.net/ChangeLog (link is in https://stardict-4.sourceforge.net/index_en.php)
  2022.
    StarDict-3.0.1.3 (Bodhisatta xxx) released.
    Support compress dictionary format!
    Some small changes!
  2022.1.
    StarDict-3.0.7 (MasterWork xxx) released.
    Port to gtk3!
    Add some babylon dictionaries.
    Add some BigDict dictionaries.
    Add some PowerWord dictionaries.
    Stardict_client add md5 salt feature and RSA encrypt feature! As StarDict-Protocol_v04.
    Thanks Anatoly Sova <anatoliysova@gmail.com> for the bgl and dsl convert patch!
    Add fortune and cal plugins.
    Add info plugin.
    Add flite TTS plugin.
    Add YouDao.com netdict plugin.
    Thanks GreenLunar for the Hebrew translation!
    Many small changes.

Optionally you may install the whole stardict package:

$ sudo apt install stardict stardict-gtk stardict-plugin stardict-plugin-espeak \
 stardict-plugin-festival stardict-plugin-info stardict-plugin-spell stardict-xmllittre

stardict-editor
===============
Run "stardict-editor" after installing it from the Ubuntu package stardict-tools (see above).

In my Ubuntu 22.04 LTS, it installed to /usr/lib/stardict-tools/ and is run like this:

$ /usr/lib/stardict-tools/stardict-editor

In the default Compile tab, press Browse and select the sorted file, e.g.
  wikt-en-ALL-yyyy-mm-dd.txt
Press Compile. The window is greyed out until processing is ready.
  If it's a big dictionary, Ubuntu may show once or many times a dialog asking
  whether you want to "Force Quit" or "Wait". Click always "Wait".
The program prints messages like this, if the conversion works:
  Building...
  [message] Conversion is over.
  [message] wikt-sv-sv-2023-02-18 wordcount: 359441.
  Done!
The program may give warnings about missing tabs for some lines but that should be ok.
The warnings look like this:
  [warning] Warning: line 12345, no tab! Skipping line.

The above conversion process produces files like:

wikt-en-ALL-yyyy-mm-dd.dict.dz
  The Stardict compatible dictionary file (for dictd compatible ones, see
   section F. below)
wikt-en-ALL-yyyy-mm-dd.idx
  The index file needed by Stardict and dictd
wikt-en-ALL-yyyy-mm-dd.ifo
  The Stardict compatible description file. It can be edited in a text editor

An example:
  
~/Downloads/stardict-tools-3.0.2/src/example.ifo:
  StarDict's dict ifo file
  version=2.4.2
  wordcount=100
  idxfilesize=100
  bookname=example
  author=the author name
  email=author@email
  website=this dictionary's project website link
  description=convert to StarDict by...
  date=2003.05.10
  sametypesequence=m

The generated ifo file, e.g. wikt-el-ALL-2023-01-19.ifo, looks something like this:

StarDict's dict ifo file
version=2.4.2
wordcount=843850
idxfilesize=20955842
bookname=wikt-el-ALL-2023-02-19
sametypesequence=m

Change the generated ifo file to look something like this:

StarDict's dict ifo file
version=2.4.2
wordcount=843850
idxfilesize=20955842
bookname=wikt-el-ALL-2023-02-19
author=Wiktionary volunteers. Converted by Joel Korhonen
email=stardict-korhoj@outlook.com
website=https://dictinfo.com
description=Stardict format, Greek Wiktionary, all languages, v.2023-Feb-19, based on entries from 2022-Nov-20
date=2023.02.19
sametypesequence=m

You may copy wikt-en-ALL-yyyy-mm-dd.dict.dz and wikt-en-ALL-yyyy-mm-dd.idx to e.g. your phone and use it with a Stardict compatible
GUI such as Colordict, or if you have installed the Stardict GUI in your PC, you can use the file with it.

F. CREATING AND INSTALLING A DICTD COMPATIBLE DICTIONARY ARCHIVE FOR A LANGUAGE

Steps in the above section D. (not necessarily E. however) need to be performed first.
Then perform the following steps in Linux:

dictzip
=======
In Ubuntu, install dictzip, which is used to produce the .dict.dz file:

$ sudo apt install dictzip

dictd
=====
For building dictd compatible dictionary archives, you don't need to be running a dictd server. It is good to install it though, because it can be used to verify the integrity of any dictionary archives you produce. In addition you can also then use the command "dict" to look up dictionary entries in your Linux...

$ sudo apt install dictd

Dictionary packages for dictd in Ubuntu
=======================================
Ubuntu repo(s) contain many prebuilt dictionaries for dictd.
You may install any you want. It works best if you only install one or two at a time.

Some example packages for 22.04 LTS (@20230218):
  sudo apt install dict-freedict-eng-fra
                   dict-freedict-lat-eng
                   dict-freedict-swe-deu
                   dict-freedict-swe-lat
                   dict-freedict-eng-spa
                   dict-freedict-swe-eng
                   dict-freedict-fin-nld
                   dict-freedict-ita-deu
                   dict-de-en

dictfmt
=======
Install dictfmt if it is not installed:

$ sudo apt install dictfmt

Joining duplicates
==================
Run the join-dupls-dictfmt-*.cmd script in Windows for the language archive you are producing. The scripts use a Java program placed in the file JoinDefinitions.jar.

E.g. for en-ALL the script is:
  join-dupls-dictfmt-en-ALL.cmd

The script(s) produce(s) files named in the format
  wikt-langcode-lang-dictfmt-dupls-joined.txt
E.g.
  wikt-en-ALL-dictfmt-dupls-joined.txt
  
(
    toformat.txt - an example in F.O.L.D.O.C. format
	\n's should be replaced by real Unix-linefeeds (real \n's) + tab (\t)
	  sed 's/\\n/\n\t/g' > sed-test.txt < headi-nodupls.txt
)

dictfmt
=======
N.b. the next step overwrites any .dz file created in step E, e.g. wikt-en-ALL-yyyy-mm-dd.dict.dz

Edit the date of the input files to the dictfmt*.sh script for the dictionary language you are processing, e.g.

# for en-ALL
$ cd en/
$ ./dictfmt-en-ALL.sh

# for fi-fi
$ cd fi/
$ ./dictfmt-fi-fi.sh

Run the script. It first copies a the public domain + CC-SA-BY copyright header to the output file. Then it copies the joined duplicates after the copyright header. The resulting file, wikt-$convLangCode-$convLang-$convDate-dict.txt, is fed as input to dictfmt:
  # For illustrative purposes, don't do manually but call the script instead
  dictfmt -f --utf8 --allchars wikt-$convLangCode-$convLang-$convDate -u http://dictinfo.com -s wikt-$convLangCode-$convLang-$convDate < wikt-$convLangCode-$convLang-$convDate-dict.tx
    -f: FILE  is  formatted  with  the headwords starting in column 0, with the
    definition indented at least one space (or tab character) on  subsequent lines.
    The third line starting in column 0 is taken as the first headword, and the
    first two lines starting in column 0 are treated as part of the
    00-database-info  header. This option was written to format the F.O.L.D.O.C.

dictfmt creates .dict and .index for the given language.

The script then calls dictzip to produces the .dict.dz file.
N.b. this step overwrites any existing .dict.dz file, but that
is normally not a problem. In step E such files were created
in a StarDict (but not dictd) compatible format, but in the
higher directory .., whilst in this step they are created in
the dictd format in language specific folders.

Verifying language's using ifo file(s) - optional
-------------------------------------------------
Run the following for a given language's ifo file, if you have created such by doing step E earlier, and want to verify the dictionary files. The ifo isn't needed for dictd as such:

$ /Downloads/stardict_3.0.6/tools/src/stardict-verify wikt-en-ALL.ifo
  [message] Verifying dictionary 'wikt-el-ALL-2023-02-19.ifo'...
  [message] Loading index file: 'wikt-el-ALL-2023-02-19.idx'...
  [message] Loading dictionary file: 'wikt-el-ALL-2023-02-19.dict.dz'...
  [message] Dictionary 'wikt-el-ALL-2023-02-19.ifo'. Verification result: OK.

Or to verify dictionaries for all languages, run:

$ for f in `ls wikt*.ifo` ; do ~/Downloads/stardict-3.0.6.3/tools/src/stardict-verify $f ; done

Installing dictd format dictionaries
------------------------------------
First make sure you are in the language specific subfolder, such as en/.
Then install a given languages .dict.dz archive like this:

$ sudo cp -vi wikt-en-ALL-yyyy-mm-dd.{dict.dz,index} /usr/share/dictd/
$ dictdconfig -l
  lists current dictionary entries. It should now show your new dictionary, e.g.:
  database wikt-en-ALL-2018-05-15
  {
   data  /usr/share/dictd/wikt-en-ALL-2018-05-15.dict.dz
   index /usr/share/dictd/wikt-en-ALL-2018-05-15.index
  }
$ sudo dictdconfig -w
  updates /var/lib/dictd/db.list
$ sudo service dictd restart
$ dictdconfig -l
  confirm the new dictionary is installed
$ dict -i wikt-en-ALL-yyyy-mm-dd
  Confirm that the header info shows OK. The copyright (from pd-header.txt) should be in the last paragraph

Testing looking up words in the dictionaries you have installed:

$ dict ἀβλεψία
  2 definitions found

  From wikt-el-el-2023-02-19 [wikt-el-el-2023-02-19]:

    ἀβλεψία
     n.
     (η) η αβλεψία στην πολυτονική γραφή
     Αρχαία ελληνικά n.
     1 τύφλωση
     2 (μεταφορικά) η αδυναμία να δει κάποιος κάτι
     3 το να είναι κάτι αόρατο

  From wikt-el-ALL-2023-02-19 [wikt-el-ALL-2023-02-19]:
  ...
